This notebook implements transfer learning using the [Resnet50](https://arxiv.org/abs/1512.03385) model to classify images in the [STL-10 dataset](https://cs.stanford.edu/~acoates/stl10/). 

## Approach
The [STL-10 dataset](http://cs.stanford.edu/~acoates/stl10/) consists of 5,000 training images and 8,000 test images that are 96 by 96 with three color channels selected from the [ImageNet](http://www.image-net.org/) dataset. (It also includes 100,000 unlabeled images to be used for unsupervised learning, but I won't be using those.) There are an equal number of images in each of 10 classes (airplane, bird, car, cat, deer, dog, horse, monkey, ship, truck) for both the train (500) and test (800) sets.

The challenge is to use [transfer learning](https://en.wikipedia.org/wiki/Transfer_learning) to create a model that predicts the classes as accurately as possible on the test set as a whole. It appears that the state of the art today is 78.66% accuracy. ([This site](https://martin-thoma.com/sota/), updated as of 2017-02, had a good list of top results for many standard datasets.) But that accuracy figure is for a different protocol than the one that I'm going to execute. That protocol entailed performing unsupervised learning on the unlabeled training images and then supervised learning on the labeled data using 10 pre-defined folds, each containing 1,000 images with the overall accuracy then reported as the average of the ten separately trained models. 

I'm going to train on all 5,000 training images, and instead of using the unlabeled images, I'm going to use weights from the pretrained [Resnet50 model](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py) included with [Pytorch](http://pytorch.org/docs/master/index.html) for transfer learning. Since Resnet50 was trained on the ImageNet dataset, the results should be excellent. I checked around the internet and found other results in the mid-90%'s using a similar approach.

I've completed Andrew Ng's original [Machine Learning course on Coursera](https://www.coursera.org/learn/machine-learning), his more recent [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) and the first two lectures of the [fast.ai deep learning course](http://course.fast.ai/). I've also completed a couple of projects building and operationalizing models in the auto insurance space, but still consider myself fairly new to deep learning. I've used [Tensorflow](https://www.tensorflow.org/), [Keras](https://keras.io/) and the [scikit-learn](http://scikit-learn.org/stable/) before so I decided to tackle this challenge with [Pytorch](http://pytorch.org/).

## Conclusion
Transfer learning based on the Resnet50 model produced excellent results in classifying images in the STL10 dataset. I was impressed with absolute results of nearly 98%. However, part of the explanation for these great results has to be because the STL10 images are a subset of the ImageNet images the Resnet50 model was trained on. We are testing on images the model was trained on.

Working through the images after the model was trained was really fun. By analyzing a few different buckets of images, I was able to develop some intuitions around why the model might have been making the predictions it was.

I ended up really liking Pytorch. The process of constructing the Dataloader class and learning about how the training loop and model worked was valuable. There were a bunch of times where I was tracking down errors and appreciated that they referred to lines in my notebook that I could trace directly. The documentation was excellent. I like how tensors are moved explicitly on and off the gpu. I liked the mental model of thinking of it as something like numpy with gpu capabilities and a differntiation engine. ([This talk](https://www.youtube.com/watch?v=LAMwEJZqesU) by Souminth Chintala, one of the developers, was an excellent orientation.) Overall, even though it is a bit lower level than Keras, the mechanics of using it seem to be closer to the concepts I've learned in my courses and readings.
